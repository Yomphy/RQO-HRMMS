{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import os\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# 超参数\n",
    "num_input = 513*151\n",
    "in_channels = 1\n",
    "features = 8\n",
    "num_hidden = 200\n",
    "num_class = 6\n",
    "batch_size = 128\n",
    "learning_rate = 0.005\n",
    "epochs = 10\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# 读取数据集\n",
    "data_path = \"D:\\\\Data_Set\\\\pyVHR\\\\MovingClass\\\\Class2\\\\Data\\\\\"\n",
    "label_path = \"D:\\\\Data_Set\\\\pyVHR\\\\MovingClass\\\\Class2\\\\Labels\\\\\"\n",
    "data_files = os.listdir(data_path)\n",
    "label_files = os.listdir(label_path)\n",
    "all_data = []\n",
    "all_label = []\n",
    "for i in range(len(data_files)):\n",
    "    data = np.loadtxt(data_path + data_files[i])\n",
    "    all_data.append(data)\n",
    "    label = np.loadtxt(label_path + label_files[i])\n",
    "    all_label.append(label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WuHP\\AppData\\Local\\Temp\\ipykernel_22292\\1104655312.py:2: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  all_label = np.array(all_label, dtype=np.int)\n"
     ]
    }
   ],
   "source": [
    "all_data = np.array(all_data)\n",
    "all_label = np.array(all_label, dtype=np.int)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "count = len(all_label)\n",
    "train = [i for i in range(count)]\n",
    "test = []\n",
    "for i in range(0, count, 4):\n",
    "    test.append(i)\n",
    "    train.remove(i)\n",
    "x_train = all_data[train]\n",
    "y_train = all_label[train]\n",
    "x_valid = all_data[test]\n",
    "y_valid = all_label[test]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "train_transform = transforms.Compose([transforms.ToTensor()])\n",
    "test_transform = transforms.Compose([transforms.ToTensor()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# 构建Dataset类训练、测试数据， 集成Dataset，复写__getitem__\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, label, transform):\n",
    "        '''\n",
    "        自制数据集的Dataset\n",
    "        '''\n",
    "        self.data = data\n",
    "        self.labels = label\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 返回第index个数据样本\n",
    "        img = self.data[index]\n",
    "        label = self.labels[index]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "train_data = MyDataset(x_train, y_train, train_transform)\n",
    "Train_loader =DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "test_data = MyDataset(x_valid, y_valid, test_transform)\n",
    "Test_loader = DataLoader(dataset=test_data, batch_size=len(test_data), shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# 搭建CNN网络\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channel=1, feature=8, num_class=2):\n",
    "        super(CNN, self).__init__()\n",
    "        self.Conv1 = nn.Conv2d(in_channels=in_channel, out_channels=feature, kernel_size=3, stride=1, padding=1)     # 卷积层1： Batch * 8 * 513 * 151\n",
    "        self.Relu1 = nn.ReLU()                               # 激活层\n",
    "        self.Pool1 = nn.MaxPool2d(kernel_size=2, stride=2)                                                           # 最大池化1：Batch * 8 * 256 * 75\n",
    "\n",
    "        self.Conv2 = nn.Conv2d(feature, feature, kernel_size=3, stride=1, padding=1)                                 # 卷积层2：  Batch * 8 * 256 * 75\n",
    "        self.Relu2 = nn.ReLU()                               # 激活层\n",
    "        self.Pool2 = nn.MaxPool2d(kernel_size=2, stride=2)                                                           # 最大池化2：Batch * 8 * 128 * 37\n",
    "\n",
    "        self.Conv3 = nn.Conv2d(feature, feature // 2, kernel_size=3, stride=1, padding=1)                            # 卷积层3：Batch * 4 * 128 * 37\n",
    "        self.Relu3 = nn.ReLU()                               # 激活层\n",
    "        self.Pool3 = nn.MaxPool2d(kernel_size=2, stride=2)                                                           # 最大池化3：Batch * 4 * 64 * 18\n",
    "\n",
    "        self.Conv4 = nn.Conv2d(feature//2, 1, kernel_size=3, stride=1, padding=1)                                    # 卷积层4：Batch * 1 * 64 * 18\n",
    "        self.Relu4 = nn.ReLU()                               # 激活层\n",
    "        self.Pool4 = nn.MaxPool2d(kernel_size=2, stride=2)                                                           # 最大池化4 Batch * 1 * 32 * 9\n",
    "\n",
    "        self.Fc = nn.Linear(32*9, num_class)               # 全连接层输出\n",
    "\n",
    "    # 参数前向传播\n",
    "    def forward(self, x):\n",
    "        x = self.Conv1(x)\n",
    "        x = self.Relu1(x)\n",
    "        x = self.Pool1(x)\n",
    "        x = self.Conv2(x)\n",
    "        x = self.Relu2(x)\n",
    "        x = self.Pool2(x)\n",
    "        x = self.Conv3(x)\n",
    "        x = self.Relu3(x)\n",
    "        x = self.Pool3(x)\n",
    "        x = self.Conv4(x)\n",
    "        x = self.Relu4(x)\n",
    "        x = self.Pool4(x)\n",
    "        x = x.reshape(x.shape[0], -1)   # [Batch, , , ] --> [Batch, ]\n",
    "        x = self.Fc(x)\n",
    "        return x\n",
    "\n",
    "# 初始化模型\n",
    "model = CNN(in_channel=in_channels, feature=features, num_class=2).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#定义损失函数和优化器\n",
    "LossFuc = nn.CrossEntropyLoss()     # 该损失函数包括了softmax，因此不需要在输出层额外添加softmax激活函数\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/30], [0/24], loss=0.0230\n",
      "[1/30], [1/24], loss=0.0102\n",
      "[1/30], [2/24], loss=0.0122\n",
      "[1/30], [3/24], loss=0.0093\n",
      "[1/30], [4/24], loss=0.0024\n",
      "[1/30], [5/24], loss=0.0043\n",
      "[1/30], [6/24], loss=0.0030\n",
      "[1/30], [7/24], loss=0.0060\n",
      "[1/30], [8/24], loss=0.0144\n",
      "[1/30], [9/24], loss=0.0145\n",
      "[1/30], [10/24], loss=0.0072\n",
      "[1/30], [11/24], loss=0.0057\n",
      "[1/30], [12/24], loss=0.0081\n",
      "[1/30], [13/24], loss=0.0103\n",
      "[1/30], [14/24], loss=0.0049\n",
      "[1/30], [15/24], loss=0.0103\n",
      "[1/30], [16/24], loss=0.0078\n",
      "[1/30], [17/24], loss=0.0115\n",
      "[1/30], [18/24], loss=0.0118\n",
      "[1/30], [19/24], loss=0.0039\n",
      "[1/30], [20/24], loss=0.0023\n",
      "[1/30], [21/24], loss=0.0088\n",
      "[1/30], [22/24], loss=0.0026\n",
      "[1/30], [23/24], loss=0.0000\n",
      "[2/30], [0/24], loss=0.0034\n",
      "[2/30], [1/24], loss=0.0041\n",
      "[2/30], [2/24], loss=0.0089\n",
      "[2/30], [3/24], loss=0.0009\n",
      "[2/30], [4/24], loss=0.0035\n",
      "[2/30], [5/24], loss=0.0034\n",
      "[2/30], [6/24], loss=0.0030\n",
      "[2/30], [7/24], loss=0.0128\n",
      "[2/30], [8/24], loss=0.0023\n",
      "[2/30], [9/24], loss=0.0022\n",
      "[2/30], [10/24], loss=0.0063\n",
      "[2/30], [11/24], loss=0.0023\n",
      "[2/30], [12/24], loss=0.0032\n",
      "[2/30], [13/24], loss=0.0031\n",
      "[2/30], [14/24], loss=0.0038\n",
      "[2/30], [15/24], loss=0.0053\n",
      "[2/30], [16/24], loss=0.0007\n",
      "[2/30], [17/24], loss=0.0017\n",
      "[2/30], [18/24], loss=0.0110\n",
      "[2/30], [19/24], loss=0.0019\n",
      "[2/30], [20/24], loss=0.0115\n",
      "[2/30], [21/24], loss=0.0012\n",
      "[2/30], [22/24], loss=0.0045\n",
      "[2/30], [23/24], loss=0.0042\n",
      "[3/30], [0/24], loss=0.0023\n",
      "[3/30], [1/24], loss=0.0039\n",
      "[3/30], [2/24], loss=0.0063\n",
      "[3/30], [3/24], loss=0.0032\n",
      "[3/30], [4/24], loss=0.0056\n",
      "[3/30], [5/24], loss=0.0016\n",
      "[3/30], [6/24], loss=0.0041\n",
      "[3/30], [7/24], loss=0.0022\n",
      "[3/30], [8/24], loss=0.0032\n",
      "[3/30], [9/24], loss=0.0023\n",
      "[3/30], [10/24], loss=0.0060\n",
      "[3/30], [11/24], loss=0.0049\n",
      "[3/30], [12/24], loss=0.0015\n",
      "[3/30], [13/24], loss=0.0043\n",
      "[3/30], [14/24], loss=0.0017\n",
      "[3/30], [15/24], loss=0.0037\n",
      "[3/30], [16/24], loss=0.0016\n",
      "[3/30], [17/24], loss=0.0073\n",
      "[3/30], [18/24], loss=0.0068\n",
      "[3/30], [19/24], loss=0.0022\n",
      "[3/30], [20/24], loss=0.0096\n",
      "[3/30], [21/24], loss=0.0022\n",
      "[3/30], [22/24], loss=0.0038\n",
      "[3/30], [23/24], loss=0.0016\n",
      "[4/30], [0/24], loss=0.0028\n",
      "[4/30], [1/24], loss=0.0025\n",
      "[4/30], [2/24], loss=0.0023\n",
      "[4/30], [3/24], loss=0.0005\n",
      "[4/30], [4/24], loss=0.0032\n",
      "[4/30], [5/24], loss=0.0018\n",
      "[4/30], [6/24], loss=0.0035\n",
      "[4/30], [7/24], loss=0.0035\n",
      "[4/30], [8/24], loss=0.0010\n",
      "[4/30], [9/24], loss=0.0076\n",
      "[4/30], [10/24], loss=0.0027\n",
      "[4/30], [11/24], loss=0.0067\n",
      "[4/30], [12/24], loss=0.0101\n",
      "[4/30], [13/24], loss=0.0017\n",
      "[4/30], [14/24], loss=0.0014\n",
      "[4/30], [15/24], loss=0.0035\n",
      "[4/30], [16/24], loss=0.0024\n",
      "[4/30], [17/24], loss=0.0153\n",
      "[4/30], [18/24], loss=0.0053\n",
      "[4/30], [19/24], loss=0.0048\n",
      "[4/30], [20/24], loss=0.0035\n",
      "[4/30], [21/24], loss=0.0070\n",
      "[4/30], [22/24], loss=0.0066\n",
      "[4/30], [23/24], loss=0.0033\n",
      "[5/30], [0/24], loss=0.0062\n",
      "[5/30], [1/24], loss=0.0034\n",
      "[5/30], [2/24], loss=0.0019\n",
      "[5/30], [3/24], loss=0.0030\n",
      "[5/30], [4/24], loss=0.0017\n",
      "[5/30], [5/24], loss=0.0067\n",
      "[5/30], [6/24], loss=0.0008\n",
      "[5/30], [7/24], loss=0.0094\n",
      "[5/30], [8/24], loss=0.0037\n",
      "[5/30], [9/24], loss=0.0020\n",
      "[5/30], [10/24], loss=0.0145\n",
      "[5/30], [11/24], loss=0.0020\n",
      "[5/30], [12/24], loss=0.0045\n",
      "[5/30], [13/24], loss=0.0021\n",
      "[5/30], [14/24], loss=0.0068\n",
      "[5/30], [15/24], loss=0.0037\n",
      "[5/30], [16/24], loss=0.0030\n",
      "[5/30], [17/24], loss=0.0031\n",
      "[5/30], [18/24], loss=0.0010\n",
      "[5/30], [19/24], loss=0.0008\n",
      "[5/30], [20/24], loss=0.0036\n",
      "[5/30], [21/24], loss=0.0043\n",
      "[5/30], [22/24], loss=0.0014\n",
      "[5/30], [23/24], loss=0.0009\n",
      "[6/30], [0/24], loss=0.0017\n",
      "[6/30], [1/24], loss=0.0045\n",
      "[6/30], [2/24], loss=0.0017\n",
      "[6/30], [3/24], loss=0.0017\n",
      "[6/30], [4/24], loss=0.0046\n",
      "[6/30], [5/24], loss=0.0066\n",
      "[6/30], [6/24], loss=0.0021\n",
      "[6/30], [7/24], loss=0.0016\n",
      "[6/30], [8/24], loss=0.0035\n",
      "[6/30], [9/24], loss=0.0004\n",
      "[6/30], [10/24], loss=0.0009\n",
      "[6/30], [11/24], loss=0.0073\n",
      "[6/30], [12/24], loss=0.0026\n",
      "[6/30], [13/24], loss=0.0021\n",
      "[6/30], [14/24], loss=0.0059\n",
      "[6/30], [15/24], loss=0.0008\n",
      "[6/30], [16/24], loss=0.0031\n",
      "[6/30], [17/24], loss=0.0017\n",
      "[6/30], [18/24], loss=0.0029\n",
      "[6/30], [19/24], loss=0.0012\n",
      "[6/30], [20/24], loss=0.0010\n",
      "[6/30], [21/24], loss=0.0057\n",
      "[6/30], [22/24], loss=0.0020\n",
      "[6/30], [23/24], loss=0.0000\n",
      "[7/30], [0/24], loss=0.0026\n",
      "[7/30], [1/24], loss=0.0009\n",
      "[7/30], [2/24], loss=0.0046\n",
      "[7/30], [3/24], loss=0.0032\n",
      "[7/30], [4/24], loss=0.0004\n",
      "[7/30], [5/24], loss=0.0006\n",
      "[7/30], [6/24], loss=0.0036\n",
      "[7/30], [7/24], loss=0.0005\n",
      "[7/30], [8/24], loss=0.0006\n",
      "[7/30], [9/24], loss=0.0057\n",
      "[7/30], [10/24], loss=0.0025\n",
      "[7/30], [11/24], loss=0.0004\n",
      "[7/30], [12/24], loss=0.0022\n",
      "[7/30], [13/24], loss=0.0013\n",
      "[7/30], [14/24], loss=0.0020\n",
      "[7/30], [15/24], loss=0.0023\n",
      "[7/30], [16/24], loss=0.0021\n",
      "[7/30], [17/24], loss=0.0003\n",
      "[7/30], [18/24], loss=0.0018\n",
      "[7/30], [19/24], loss=0.0010\n",
      "[7/30], [20/24], loss=0.0029\n",
      "[7/30], [21/24], loss=0.0014\n",
      "[7/30], [22/24], loss=0.0014\n",
      "[7/30], [23/24], loss=0.0000\n",
      "[8/30], [0/24], loss=0.0007\n",
      "[8/30], [1/24], loss=0.0013\n",
      "[8/30], [2/24], loss=0.0059\n",
      "[8/30], [3/24], loss=0.0026\n",
      "[8/30], [4/24], loss=0.0005\n",
      "[8/30], [5/24], loss=0.0011\n",
      "[8/30], [6/24], loss=0.0021\n",
      "[8/30], [7/24], loss=0.0016\n",
      "[8/30], [8/24], loss=0.0022\n",
      "[8/30], [9/24], loss=0.0006\n",
      "[8/30], [10/24], loss=0.0013\n",
      "[8/30], [11/24], loss=0.0024\n",
      "[8/30], [12/24], loss=0.0004\n",
      "[8/30], [13/24], loss=0.0029\n",
      "[8/30], [14/24], loss=0.0021\n",
      "[8/30], [15/24], loss=0.0031\n",
      "[8/30], [16/24], loss=0.0002\n",
      "[8/30], [17/24], loss=0.0007\n",
      "[8/30], [18/24], loss=0.0026\n",
      "[8/30], [19/24], loss=0.0015\n",
      "[8/30], [20/24], loss=0.0012\n",
      "[8/30], [21/24], loss=0.0012\n",
      "[8/30], [22/24], loss=0.0016\n",
      "[8/30], [23/24], loss=0.0008\n",
      "[9/30], [0/24], loss=0.0010\n",
      "[9/30], [1/24], loss=0.0012\n",
      "[9/30], [2/24], loss=0.0018\n",
      "[9/30], [3/24], loss=0.0028\n",
      "[9/30], [4/24], loss=0.0012\n",
      "[9/30], [5/24], loss=0.0011\n",
      "[9/30], [6/24], loss=0.0011\n",
      "[9/30], [7/24], loss=0.0006\n",
      "[9/30], [8/24], loss=0.0011\n",
      "[9/30], [9/24], loss=0.0027\n",
      "[9/30], [10/24], loss=0.0007\n",
      "[9/30], [11/24], loss=0.0006\n",
      "[9/30], [12/24], loss=0.0007\n",
      "[9/30], [13/24], loss=0.0020\n",
      "[9/30], [14/24], loss=0.0011\n",
      "[9/30], [15/24], loss=0.0004\n",
      "[9/30], [16/24], loss=0.0007\n",
      "[9/30], [17/24], loss=0.0027\n",
      "[9/30], [18/24], loss=0.0006\n",
      "[9/30], [19/24], loss=0.0016\n",
      "[9/30], [20/24], loss=0.0059\n",
      "[9/30], [21/24], loss=0.0024\n",
      "[9/30], [22/24], loss=0.0017\n",
      "[9/30], [23/24], loss=0.0028\n",
      "[10/30], [0/24], loss=0.0020\n",
      "[10/30], [1/24], loss=0.0009\n",
      "[10/30], [2/24], loss=0.0025\n",
      "[10/30], [3/24], loss=0.0017\n",
      "[10/30], [4/24], loss=0.0013\n",
      "[10/30], [5/24], loss=0.0007\n",
      "[10/30], [6/24], loss=0.0021\n",
      "[10/30], [7/24], loss=0.0007\n",
      "[10/30], [8/24], loss=0.0015\n",
      "[10/30], [9/24], loss=0.0047\n",
      "[10/30], [10/24], loss=0.0027\n",
      "[10/30], [11/24], loss=0.0001\n",
      "[10/30], [12/24], loss=0.0055\n",
      "[10/30], [13/24], loss=0.0018\n",
      "[10/30], [14/24], loss=0.0007\n",
      "[10/30], [15/24], loss=0.0015\n",
      "[10/30], [16/24], loss=0.0015\n",
      "[10/30], [17/24], loss=0.0002\n",
      "[10/30], [18/24], loss=0.0029\n",
      "[10/30], [19/24], loss=0.0049\n",
      "[10/30], [20/24], loss=0.0003\n",
      "[10/30], [21/24], loss=0.0024\n",
      "[10/30], [22/24], loss=0.0011\n",
      "[10/30], [23/24], loss=0.0000\n",
      "[11/30], [0/24], loss=0.0022\n",
      "[11/30], [1/24], loss=0.0072\n",
      "[11/30], [2/24], loss=0.0017\n",
      "[11/30], [3/24], loss=0.0016\n",
      "[11/30], [4/24], loss=0.0016\n",
      "[11/30], [5/24], loss=0.0017\n",
      "[11/30], [6/24], loss=0.0005\n",
      "[11/30], [7/24], loss=0.0005\n",
      "[11/30], [8/24], loss=0.0012\n",
      "[11/30], [9/24], loss=0.0018\n",
      "[11/30], [10/24], loss=0.0016\n",
      "[11/30], [11/24], loss=0.0016\n",
      "[11/30], [12/24], loss=0.0019\n",
      "[11/30], [13/24], loss=0.0007\n",
      "[11/30], [14/24], loss=0.0011\n",
      "[11/30], [15/24], loss=0.0006\n",
      "[11/30], [16/24], loss=0.0005\n",
      "[11/30], [17/24], loss=0.0013\n",
      "[11/30], [18/24], loss=0.0028\n",
      "[11/30], [19/24], loss=0.0006\n",
      "[11/30], [20/24], loss=0.0013\n",
      "[11/30], [21/24], loss=0.0016\n",
      "[11/30], [22/24], loss=0.0007\n",
      "[11/30], [23/24], loss=0.0099\n",
      "[12/30], [0/24], loss=0.0017\n",
      "[12/30], [1/24], loss=0.0047\n",
      "[12/30], [2/24], loss=0.0185\n",
      "[12/30], [3/24], loss=0.0008\n",
      "[12/30], [4/24], loss=0.0033\n",
      "[12/30], [5/24], loss=0.0027\n",
      "[12/30], [6/24], loss=0.0182\n",
      "[12/30], [7/24], loss=0.0029\n",
      "[12/30], [8/24], loss=0.0130\n",
      "[12/30], [9/24], loss=0.0007\n",
      "[12/30], [10/24], loss=0.0008\n",
      "[12/30], [11/24], loss=0.0246\n",
      "[12/30], [12/24], loss=0.0029\n",
      "[12/30], [13/24], loss=0.0304\n",
      "[12/30], [14/24], loss=0.0057\n",
      "[12/30], [15/24], loss=0.0005\n",
      "[12/30], [16/24], loss=0.1553\n",
      "[12/30], [17/24], loss=0.0013\n",
      "[12/30], [18/24], loss=0.0021\n",
      "[12/30], [19/24], loss=0.1323\n",
      "[12/30], [20/24], loss=0.0819\n",
      "[12/30], [21/24], loss=0.0443\n",
      "[12/30], [22/24], loss=0.0697\n",
      "[12/30], [23/24], loss=0.3548\n",
      "[13/30], [0/24], loss=0.0182\n",
      "[13/30], [1/24], loss=0.4955\n",
      "[13/30], [2/24], loss=0.1515\n",
      "[13/30], [3/24], loss=0.0935\n",
      "[13/30], [4/24], loss=0.2055\n",
      "[13/30], [5/24], loss=0.5441\n",
      "[13/30], [6/24], loss=0.1922\n",
      "[13/30], [7/24], loss=0.0423\n",
      "[13/30], [8/24], loss=0.5469\n",
      "[13/30], [9/24], loss=0.5873\n",
      "[13/30], [10/24], loss=0.3391\n",
      "[13/30], [11/24], loss=0.2790\n",
      "[13/30], [12/24], loss=0.1334\n",
      "[13/30], [13/24], loss=0.1966\n",
      "[13/30], [14/24], loss=0.2815\n",
      "[13/30], [15/24], loss=0.1435\n",
      "[13/30], [16/24], loss=0.1174\n",
      "[13/30], [17/24], loss=0.2039\n",
      "[13/30], [18/24], loss=0.0312\n",
      "[13/30], [19/24], loss=0.1177\n",
      "[13/30], [20/24], loss=0.1228\n",
      "[13/30], [21/24], loss=0.1881\n",
      "[13/30], [22/24], loss=0.0387\n",
      "[13/30], [23/24], loss=0.0037\n",
      "[14/30], [0/24], loss=0.0184\n",
      "[14/30], [1/24], loss=0.0343\n",
      "[14/30], [2/24], loss=0.0241\n",
      "[14/30], [3/24], loss=0.0855\n",
      "[14/30], [4/24], loss=0.0223\n",
      "[14/30], [5/24], loss=0.0075\n",
      "[14/30], [6/24], loss=0.0380\n",
      "[14/30], [7/24], loss=0.0635\n",
      "[14/30], [8/24], loss=0.1353\n",
      "[14/30], [9/24], loss=0.0225\n",
      "[14/30], [10/24], loss=0.0433\n",
      "[14/30], [11/24], loss=0.1068\n",
      "[14/30], [12/24], loss=0.0200\n",
      "[14/30], [13/24], loss=0.0165\n",
      "[14/30], [14/24], loss=0.0724\n",
      "[14/30], [15/24], loss=0.0195\n",
      "[14/30], [16/24], loss=0.0324\n",
      "[14/30], [17/24], loss=0.0317\n",
      "[14/30], [18/24], loss=0.0206\n",
      "[14/30], [19/24], loss=0.0141\n",
      "[14/30], [20/24], loss=0.0428\n",
      "[14/30], [21/24], loss=0.0522\n",
      "[14/30], [22/24], loss=0.0180\n",
      "[14/30], [23/24], loss=0.0280\n",
      "[15/30], [0/24], loss=0.0285\n",
      "[15/30], [1/24], loss=0.0462\n",
      "[15/30], [2/24], loss=0.0276\n",
      "[15/30], [3/24], loss=0.0124\n",
      "[15/30], [4/24], loss=0.0049\n",
      "[15/30], [5/24], loss=0.0171\n",
      "[15/30], [6/24], loss=0.0228\n",
      "[15/30], [7/24], loss=0.0447\n",
      "[15/30], [8/24], loss=0.0202\n",
      "[15/30], [9/24], loss=0.0042\n",
      "[15/30], [10/24], loss=0.0131\n",
      "[15/30], [11/24], loss=0.0205\n",
      "[15/30], [12/24], loss=0.0280\n",
      "[15/30], [13/24], loss=0.0201\n",
      "[15/30], [14/24], loss=0.0156\n",
      "[15/30], [15/24], loss=0.0160\n",
      "[15/30], [16/24], loss=0.0200\n",
      "[15/30], [17/24], loss=0.0206\n",
      "[15/30], [18/24], loss=0.0262\n",
      "[15/30], [19/24], loss=0.0063\n",
      "[15/30], [20/24], loss=0.0046\n",
      "[15/30], [21/24], loss=0.0196\n",
      "[15/30], [22/24], loss=0.0138\n",
      "[15/30], [23/24], loss=0.0001\n",
      "[16/30], [0/24], loss=0.0084\n",
      "[16/30], [1/24], loss=0.0074\n",
      "[16/30], [2/24], loss=0.0087\n",
      "[16/30], [3/24], loss=0.0119\n",
      "[16/30], [4/24], loss=0.0106\n",
      "[16/30], [5/24], loss=0.0165\n",
      "[16/30], [6/24], loss=0.0065\n",
      "[16/30], [7/24], loss=0.0071\n",
      "[16/30], [8/24], loss=0.0198\n",
      "[16/30], [9/24], loss=0.0156\n",
      "[16/30], [10/24], loss=0.0229\n",
      "[16/30], [11/24], loss=0.0144\n",
      "[16/30], [12/24], loss=0.0192\n",
      "[16/30], [13/24], loss=0.0206\n",
      "[16/30], [14/24], loss=0.0091\n",
      "[16/30], [15/24], loss=0.0174\n",
      "[16/30], [16/24], loss=0.0136\n",
      "[16/30], [17/24], loss=0.0032\n",
      "[16/30], [18/24], loss=0.0014\n",
      "[16/30], [19/24], loss=0.0064\n",
      "[16/30], [20/24], loss=0.0120\n",
      "[16/30], [21/24], loss=0.0013\n",
      "[16/30], [22/24], loss=0.0350\n",
      "[16/30], [23/24], loss=0.0000\n",
      "[17/30], [0/24], loss=0.0119\n",
      "[17/30], [1/24], loss=0.0047\n",
      "[17/30], [2/24], loss=0.0071\n",
      "[17/30], [3/24], loss=0.0017\n",
      "[17/30], [4/24], loss=0.0063\n",
      "[17/30], [5/24], loss=0.0163\n",
      "[17/30], [6/24], loss=0.0043\n",
      "[17/30], [7/24], loss=0.0120\n",
      "[17/30], [8/24], loss=0.0252\n",
      "[17/30], [9/24], loss=0.0088\n",
      "[17/30], [10/24], loss=0.0064\n",
      "[17/30], [11/24], loss=0.0007\n",
      "[17/30], [12/24], loss=0.0067\n",
      "[17/30], [13/24], loss=0.0024\n",
      "[17/30], [14/24], loss=0.0033\n",
      "[17/30], [15/24], loss=0.0135\n",
      "[17/30], [16/24], loss=0.0223\n",
      "[17/30], [17/24], loss=0.0048\n",
      "[17/30], [18/24], loss=0.0165\n",
      "[17/30], [19/24], loss=0.0049\n",
      "[17/30], [20/24], loss=0.0115\n",
      "[17/30], [21/24], loss=0.0050\n",
      "[17/30], [22/24], loss=0.0096\n",
      "[17/30], [23/24], loss=0.0001\n",
      "[18/30], [0/24], loss=0.0053\n",
      "[18/30], [1/24], loss=0.0023\n",
      "[18/30], [2/24], loss=0.0061\n",
      "[18/30], [3/24], loss=0.0081\n",
      "[18/30], [4/24], loss=0.0075\n",
      "[18/30], [5/24], loss=0.0021\n",
      "[18/30], [6/24], loss=0.0107\n",
      "[18/30], [7/24], loss=0.0072\n",
      "[18/30], [8/24], loss=0.0020\n",
      "[18/30], [9/24], loss=0.0036\n",
      "[18/30], [10/24], loss=0.0080\n",
      "[18/30], [11/24], loss=0.0051\n",
      "[18/30], [12/24], loss=0.0034\n",
      "[18/30], [13/24], loss=0.0035\n",
      "[18/30], [14/24], loss=0.0115\n",
      "[18/30], [15/24], loss=0.0063\n",
      "[18/30], [16/24], loss=0.0041\n",
      "[18/30], [17/24], loss=0.0178\n",
      "[18/30], [18/24], loss=0.0089\n",
      "[18/30], [19/24], loss=0.0029\n",
      "[18/30], [20/24], loss=0.0142\n",
      "[18/30], [21/24], loss=0.0120\n",
      "[18/30], [22/24], loss=0.0072\n",
      "[18/30], [23/24], loss=0.0013\n",
      "[19/30], [0/24], loss=0.0043\n",
      "[19/30], [1/24], loss=0.0110\n",
      "[19/30], [2/24], loss=0.0035\n",
      "[19/30], [3/24], loss=0.0036\n",
      "[19/30], [4/24], loss=0.0053\n",
      "[19/30], [5/24], loss=0.0036\n",
      "[19/30], [6/24], loss=0.0142\n",
      "[19/30], [7/24], loss=0.0017\n",
      "[19/30], [8/24], loss=0.0033\n",
      "[19/30], [9/24], loss=0.0062\n",
      "[19/30], [10/24], loss=0.0044\n",
      "[19/30], [11/24], loss=0.0056\n",
      "[19/30], [12/24], loss=0.0034\n",
      "[19/30], [13/24], loss=0.0076\n",
      "[19/30], [14/24], loss=0.0079\n",
      "[19/30], [15/24], loss=0.0051\n",
      "[19/30], [16/24], loss=0.0016\n",
      "[19/30], [17/24], loss=0.0126\n",
      "[19/30], [18/24], loss=0.0028\n",
      "[19/30], [19/24], loss=0.0035\n",
      "[19/30], [20/24], loss=0.0082\n",
      "[19/30], [21/24], loss=0.0037\n",
      "[19/30], [22/24], loss=0.0042\n",
      "[19/30], [23/24], loss=0.0000\n",
      "[20/30], [0/24], loss=0.0083\n",
      "[20/30], [1/24], loss=0.0047\n",
      "[20/30], [2/24], loss=0.0153\n",
      "[20/30], [3/24], loss=0.0018\n",
      "[20/30], [4/24], loss=0.0037\n",
      "[20/30], [5/24], loss=0.0043\n",
      "[20/30], [6/24], loss=0.0005\n",
      "[20/30], [7/24], loss=0.0011\n",
      "[20/30], [8/24], loss=0.0034\n",
      "[20/30], [9/24], loss=0.0044\n",
      "[20/30], [10/24], loss=0.0048\n",
      "[20/30], [11/24], loss=0.0013\n",
      "[20/30], [12/24], loss=0.0051\n",
      "[20/30], [13/24], loss=0.0002\n",
      "[20/30], [14/24], loss=0.0028\n",
      "[20/30], [15/24], loss=0.0066\n",
      "[20/30], [16/24], loss=0.0118\n",
      "[20/30], [17/24], loss=0.0061\n",
      "[20/30], [18/24], loss=0.0063\n",
      "[20/30], [19/24], loss=0.0007\n",
      "[20/30], [20/24], loss=0.0010\n",
      "[20/30], [21/24], loss=0.0037\n",
      "[20/30], [22/24], loss=0.0032\n",
      "[20/30], [23/24], loss=0.0072\n",
      "[21/30], [0/24], loss=0.0010\n",
      "[21/30], [1/24], loss=0.0042\n",
      "[21/30], [2/24], loss=0.0058\n",
      "[21/30], [3/24], loss=0.0032\n",
      "[21/30], [4/24], loss=0.0042\n",
      "[21/30], [5/24], loss=0.0025\n",
      "[21/30], [6/24], loss=0.0077\n",
      "[21/30], [7/24], loss=0.0045\n",
      "[21/30], [8/24], loss=0.0039\n",
      "[21/30], [9/24], loss=0.0017\n",
      "[21/30], [10/24], loss=0.0034\n",
      "[21/30], [11/24], loss=0.0039\n",
      "[21/30], [12/24], loss=0.0024\n",
      "[21/30], [13/24], loss=0.0068\n",
      "[21/30], [14/24], loss=0.0027\n",
      "[21/30], [15/24], loss=0.0056\n",
      "[21/30], [16/24], loss=0.0021\n",
      "[21/30], [17/24], loss=0.0153\n",
      "[21/30], [18/24], loss=0.0021\n",
      "[21/30], [19/24], loss=0.0022\n",
      "[21/30], [20/24], loss=0.0071\n",
      "[21/30], [21/24], loss=0.0019\n",
      "[21/30], [22/24], loss=0.0053\n",
      "[21/30], [23/24], loss=0.0063\n",
      "[22/30], [0/24], loss=0.0070\n",
      "[22/30], [1/24], loss=0.0039\n",
      "[22/30], [2/24], loss=0.0011\n",
      "[22/30], [3/24], loss=0.0008\n",
      "[22/30], [4/24], loss=0.0031\n",
      "[22/30], [5/24], loss=0.0012\n",
      "[22/30], [6/24], loss=0.0032\n",
      "[22/30], [7/24], loss=0.0046\n",
      "[22/30], [8/24], loss=0.0065\n",
      "[22/30], [9/24], loss=0.0035\n",
      "[22/30], [10/24], loss=0.0050\n",
      "[22/30], [11/24], loss=0.0015\n",
      "[22/30], [12/24], loss=0.0007\n",
      "[22/30], [13/24], loss=0.0013\n",
      "[22/30], [14/24], loss=0.0034\n",
      "[22/30], [15/24], loss=0.0026\n",
      "[22/30], [16/24], loss=0.0024\n",
      "[22/30], [17/24], loss=0.0044\n",
      "[22/30], [18/24], loss=0.0073\n",
      "[22/30], [19/24], loss=0.0027\n",
      "[22/30], [20/24], loss=0.0189\n",
      "[22/30], [21/24], loss=0.0044\n",
      "[22/30], [22/24], loss=0.0027\n",
      "[22/30], [23/24], loss=0.0083\n",
      "[23/30], [0/24], loss=0.0093\n",
      "[23/30], [1/24], loss=0.0035\n",
      "[23/30], [2/24], loss=0.0023\n",
      "[23/30], [3/24], loss=0.0029\n",
      "[23/30], [4/24], loss=0.0032\n",
      "[23/30], [5/24], loss=0.0051\n",
      "[23/30], [6/24], loss=0.0068\n",
      "[23/30], [7/24], loss=0.0069\n",
      "[23/30], [8/24], loss=0.0053\n",
      "[23/30], [9/24], loss=0.0003\n",
      "[23/30], [10/24], loss=0.0008\n",
      "[23/30], [11/24], loss=0.0058\n",
      "[23/30], [12/24], loss=0.0024\n",
      "[23/30], [13/24], loss=0.0022\n",
      "[23/30], [14/24], loss=0.0008\n",
      "[23/30], [15/24], loss=0.0021\n",
      "[23/30], [16/24], loss=0.0040\n",
      "[23/30], [17/24], loss=0.0022\n",
      "[23/30], [18/24], loss=0.0031\n",
      "[23/30], [19/24], loss=0.0014\n",
      "[23/30], [20/24], loss=0.0014\n",
      "[23/30], [21/24], loss=0.0014\n",
      "[23/30], [22/24], loss=0.0049\n",
      "[23/30], [23/24], loss=0.0024\n",
      "[24/30], [0/24], loss=0.0024\n",
      "[24/30], [1/24], loss=0.0034\n",
      "[24/30], [2/24], loss=0.0019\n",
      "[24/30], [3/24], loss=0.0023\n",
      "[24/30], [4/24], loss=0.0003\n",
      "[24/30], [5/24], loss=0.0019\n",
      "[24/30], [6/24], loss=0.0026\n",
      "[24/30], [7/24], loss=0.0062\n",
      "[24/30], [8/24], loss=0.0023\n",
      "[24/30], [9/24], loss=0.0005\n",
      "[24/30], [10/24], loss=0.0023\n",
      "[24/30], [11/24], loss=0.0016\n",
      "[24/30], [12/24], loss=0.0038\n",
      "[24/30], [13/24], loss=0.0031\n",
      "[24/30], [14/24], loss=0.0044\n",
      "[24/30], [15/24], loss=0.0011\n",
      "[24/30], [16/24], loss=0.0027\n",
      "[24/30], [17/24], loss=0.0019\n",
      "[24/30], [18/24], loss=0.0017\n",
      "[24/30], [19/24], loss=0.0058\n",
      "[24/30], [20/24], loss=0.0015\n",
      "[24/30], [21/24], loss=0.0036\n",
      "[24/30], [22/24], loss=0.0036\n",
      "[24/30], [23/24], loss=0.0012\n",
      "[25/30], [0/24], loss=0.0015\n",
      "[25/30], [1/24], loss=0.0010\n",
      "[25/30], [2/24], loss=0.0021\n",
      "[25/30], [3/24], loss=0.0014\n",
      "[25/30], [4/24], loss=0.0040\n",
      "[25/30], [5/24], loss=0.0030\n",
      "[25/30], [6/24], loss=0.0031\n",
      "[25/30], [7/24], loss=0.0017\n",
      "[25/30], [8/24], loss=0.0003\n",
      "[25/30], [9/24], loss=0.0011\n",
      "[25/30], [10/24], loss=0.0027\n",
      "[25/30], [11/24], loss=0.0012\n",
      "[25/30], [12/24], loss=0.0017\n",
      "[25/30], [13/24], loss=0.0023\n",
      "[25/30], [14/24], loss=0.0024\n",
      "[25/30], [15/24], loss=0.0022\n",
      "[25/30], [16/24], loss=0.0026\n",
      "[25/30], [17/24], loss=0.0007\n",
      "[25/30], [18/24], loss=0.0081\n",
      "[25/30], [19/24], loss=0.0013\n",
      "[25/30], [20/24], loss=0.0007\n",
      "[25/30], [21/24], loss=0.0007\n",
      "[25/30], [22/24], loss=0.0010\n",
      "[25/30], [23/24], loss=0.0000\n",
      "[26/30], [0/24], loss=0.0007\n",
      "[26/30], [1/24], loss=0.0022\n",
      "[26/30], [2/24], loss=0.0019\n",
      "[26/30], [3/24], loss=0.0007\n",
      "[26/30], [4/24], loss=0.0034\n",
      "[26/30], [5/24], loss=0.0007\n",
      "[26/30], [6/24], loss=0.0020\n",
      "[26/30], [7/24], loss=0.0014\n",
      "[26/30], [8/24], loss=0.0024\n",
      "[26/30], [9/24], loss=0.0007\n",
      "[26/30], [10/24], loss=0.0013\n",
      "[26/30], [11/24], loss=0.0002\n",
      "[26/30], [12/24], loss=0.0034\n",
      "[26/30], [13/24], loss=0.0053\n",
      "[26/30], [14/24], loss=0.0012\n",
      "[26/30], [15/24], loss=0.0021\n",
      "[26/30], [16/24], loss=0.0008\n",
      "[26/30], [17/24], loss=0.0015\n",
      "[26/30], [18/24], loss=0.0016\n",
      "[26/30], [19/24], loss=0.0023\n",
      "[26/30], [20/24], loss=0.0009\n",
      "[26/30], [21/24], loss=0.0012\n",
      "[26/30], [22/24], loss=0.0016\n",
      "[26/30], [23/24], loss=0.0005\n",
      "[27/30], [0/24], loss=0.0008\n",
      "[27/30], [1/24], loss=0.0032\n",
      "[27/30], [2/24], loss=0.0021\n",
      "[27/30], [3/24], loss=0.0007\n",
      "[27/30], [4/24], loss=0.0006\n",
      "[27/30], [5/24], loss=0.0013\n",
      "[27/30], [6/24], loss=0.0014\n",
      "[27/30], [7/24], loss=0.0007\n",
      "[27/30], [8/24], loss=0.0009\n",
      "[27/30], [9/24], loss=0.0018\n",
      "[27/30], [10/24], loss=0.0043\n",
      "[27/30], [11/24], loss=0.0015\n",
      "[27/30], [12/24], loss=0.0012\n",
      "[27/30], [13/24], loss=0.0003\n",
      "[27/30], [14/24], loss=0.0025\n",
      "[27/30], [15/24], loss=0.0010\n",
      "[27/30], [16/24], loss=0.0014\n",
      "[27/30], [17/24], loss=0.0007\n",
      "[27/30], [18/24], loss=0.0027\n",
      "[27/30], [19/24], loss=0.0019\n",
      "[27/30], [20/24], loss=0.0007\n",
      "[27/30], [21/24], loss=0.0017\n",
      "[27/30], [22/24], loss=0.0014\n",
      "[27/30], [23/24], loss=0.0000\n",
      "[28/30], [0/24], loss=0.0019\n",
      "[28/30], [1/24], loss=0.0030\n",
      "[28/30], [2/24], loss=0.0015\n",
      "[28/30], [3/24], loss=0.0008\n",
      "[28/30], [4/24], loss=0.0006\n",
      "[28/30], [5/24], loss=0.0027\n",
      "[28/30], [6/24], loss=0.0004\n",
      "[28/30], [7/24], loss=0.0008\n",
      "[28/30], [8/24], loss=0.0012\n",
      "[28/30], [9/24], loss=0.0015\n",
      "[28/30], [10/24], loss=0.0015\n",
      "[28/30], [11/24], loss=0.0018\n",
      "[28/30], [12/24], loss=0.0015\n",
      "[28/30], [13/24], loss=0.0031\n",
      "[28/30], [14/24], loss=0.0021\n",
      "[28/30], [15/24], loss=0.0049\n",
      "[28/30], [16/24], loss=0.0007\n",
      "[28/30], [17/24], loss=0.0014\n",
      "[28/30], [18/24], loss=0.0005\n",
      "[28/30], [19/24], loss=0.0008\n",
      "[28/30], [20/24], loss=0.0013\n",
      "[28/30], [21/24], loss=0.0009\n",
      "[28/30], [22/24], loss=0.0002\n",
      "[28/30], [23/24], loss=0.0000\n",
      "[29/30], [0/24], loss=0.0008\n",
      "[29/30], [1/24], loss=0.0014\n",
      "[29/30], [2/24], loss=0.0017\n",
      "[29/30], [3/24], loss=0.0042\n",
      "[29/30], [4/24], loss=0.0025\n",
      "[29/30], [5/24], loss=0.0005\n",
      "[29/30], [6/24], loss=0.0010\n",
      "[29/30], [7/24], loss=0.0003\n",
      "[29/30], [8/24], loss=0.0005\n",
      "[29/30], [9/24], loss=0.0011\n",
      "[29/30], [10/24], loss=0.0021\n",
      "[29/30], [11/24], loss=0.0012\n",
      "[29/30], [12/24], loss=0.0015\n",
      "[29/30], [13/24], loss=0.0004\n",
      "[29/30], [14/24], loss=0.0011\n",
      "[29/30], [15/24], loss=0.0027\n",
      "[29/30], [16/24], loss=0.0006\n",
      "[29/30], [17/24], loss=0.0007\n",
      "[29/30], [18/24], loss=0.0011\n",
      "[29/30], [19/24], loss=0.0008\n",
      "[29/30], [20/24], loss=0.0016\n",
      "[29/30], [21/24], loss=0.0013\n",
      "[29/30], [22/24], loss=0.0014\n",
      "[29/30], [23/24], loss=0.0000\n",
      "[30/30], [0/24], loss=0.0010\n",
      "[30/30], [1/24], loss=0.0017\n",
      "[30/30], [2/24], loss=0.0008\n",
      "[30/30], [3/24], loss=0.0036\n",
      "[30/30], [4/24], loss=0.0013\n",
      "[30/30], [5/24], loss=0.0006\n",
      "[30/30], [6/24], loss=0.0007\n",
      "[30/30], [7/24], loss=0.0014\n",
      "[30/30], [8/24], loss=0.0007\n",
      "[30/30], [9/24], loss=0.0019\n",
      "[30/30], [10/24], loss=0.0006\n",
      "[30/30], [11/24], loss=0.0008\n",
      "[30/30], [12/24], loss=0.0007\n",
      "[30/30], [13/24], loss=0.0012\n",
      "[30/30], [14/24], loss=0.0008\n",
      "[30/30], [15/24], loss=0.0038\n",
      "[30/30], [16/24], loss=0.0014\n",
      "[30/30], [17/24], loss=0.0010\n",
      "[30/30], [18/24], loss=0.0004\n",
      "[30/30], [19/24], loss=0.0005\n",
      "[30/30], [20/24], loss=0.0011\n",
      "[30/30], [21/24], loss=0.0012\n",
      "[30/30], [22/24], loss=0.0010\n",
      "[30/30], [23/24], loss=0.0000\n"
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "loss_lst = []\n",
    "epochs = 30\n",
    "for epoch in range(epochs):\n",
    "    loss_epoch = 0.0\n",
    "    for batch_index, (images, labels) in enumerate(Train_loader):\n",
    "        images = images.to(torch.float32)\n",
    "        images  = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "        # 计算损失\n",
    "        loss = LossFuc(outputs, labels.long())\n",
    "        loss_epoch += loss\n",
    "\n",
    "        # 梯度后向传播\n",
    "        optimizer.zero_grad()   # 置零\n",
    "        loss.backward()         # 向后传\n",
    "        optimizer.step()        # 更新\n",
    "\n",
    "        # if batch_index % 100 == 0:\n",
    "        print('[{}/{}], [{}/{}], loss={:.4f}'.format(epoch+1, epochs, batch_index, len(Train_loader), loss))\n",
    "    loss_lst.append(loss_epoch / (batch_index + 1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.008100616745650768,\n 0.0043912469409406185,\n 0.0038275287952274084,\n 0.00430113822221756,\n 0.0037740988191217184,\n 0.0027319069486111403,\n 0.001847862615250051,\n 0.001686320174485445,\n 0.0016025400254875422,\n 0.0018242374062538147,\n 0.0019270607735961676,\n 0.040538933128118515,\n 0.21139827370643616,\n 0.04039347916841507,\n 0.018875114619731903,\n 0.012045796029269695,\n 0.00857715867459774,\n 0.0067106811329722404,\n 0.005308560095727444,\n 0.004519590176641941,\n 0.00440954277291894,\n 0.004178288858383894,\n 0.0033514010719954967,\n 0.0025760724674910307,\n 0.0019516320899128914,\n 0.0016667889431118965,\n 0.0014591312501579523,\n 0.0014677181607112288,\n 0.0012731601018458605,\n 0.001169492257758975]"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_data = [i.data.cpu().item() for i in loss_lst]\n",
    "loss_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0.5, 0, '训练轮次')"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(np.arange(0, epochs), np.array(loss_data))\n",
    "plt.xticks([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14], [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15])\n",
    "plt.ylabel(\"Loss\", fontproperties='Times New Roman', fontsize=18)\n",
    "plt.xlabel(\"训练轮次\", fontproperties='SimSun', fontsize=18)\n",
    "# plt.savefig(r\"D:\\OneDrive\\桌面\\绘图1.svg\", dpi=500)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集精度为：98.88211059570312%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct_num = 0\n",
    "    total_num = 0\n",
    "    for images, labels in Test_loader:\n",
    "        images = images.to(torch.float32)\n",
    "        images  = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        correct_num = (predictions==labels).sum()\n",
    "        total_num = (predictions.size(0))\n",
    "        print(\"测试集精度为：{}%\".format(correct_num/total_num*100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n       device='cuda:0', dtype=torch.int32)"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "984\n"
     ]
    }
   ],
   "source": [
    "t_count = 0\n",
    "f_count = 0\n",
    "with torch.no_grad():\n",
    "    t_f_num = 0\n",
    "    f_t_num = 0\n",
    "    t_t_num = 0\n",
    "    f_f_num = 0\n",
    "    i = 0\n",
    "    for images, labels in Test_loader:\n",
    "        for i in range(len(images)):\n",
    "            image = images[i].to(torch.float32).to(device)\n",
    "            label = labels[i]\n",
    "            output = model(image)\n",
    "            _, prediction = torch.max(output, 1)\n",
    "            if label == 1:\n",
    "                t_count += 1\n",
    "                if prediction == 1:\n",
    "                    t_t_num += 1\n",
    "                elif prediction == 0:\n",
    "                    t_f_num += 1\n",
    "            if label == 0:\n",
    "                f_count += 1\n",
    "                if prediction == 0:\n",
    "                    f_f_num += 1\n",
    "                elif prediction == 1:\n",
    "                    f_t_num += 1\n",
    "        print(len(images))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "984 645 7\n",
      "984 645 638\n",
      "984 339 4\n",
      "984 339 335\n"
     ]
    }
   ],
   "source": [
    "test_count = len(images)\n",
    "print(test_count, t_count, t_f_num)\n",
    "print(test_count, t_count, t_t_num)\n",
    "print(test_count, f_count, f_t_num)\n",
    "print(test_count, f_count, f_f_num)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[638,   7],\n       [  4, 335]])"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confun_matrix = np. array([[t_t_num, t_f_num], [f_t_num, f_f_num]])\n",
    "# confun_matrix = np. array([[t_t_num / t_count, t_f_num / t_count], [f_t_num / f_count, f_f_num / f_count]])\n",
    "confun_matrix = np.around(confun_matrix, decimals=4)\n",
    "confun_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,8))\n",
    "# plt.text(-0.2,0, str(confun_matrix[0,0]), fontsize=22, fontdict={'color': 'white'})\n",
    "# plt.text(-0.2,1, str(confun_matrix[1,0]), fontsize=22)\n",
    "# plt.text(0.8,0, str(confun_matrix[0,1]), fontsize=22)\n",
    "# plt.text(0.8,1, str(confun_matrix[1,1]), fontsize=22, fontdict={'color': 'white'})\n",
    "plt.text(-0.1,0, str(confun_matrix[0,0]), fontsize=22, fontdict={'color': 'white'})\n",
    "plt.text(0,1, str(confun_matrix[1,0]), fontsize=22)\n",
    "plt.text(1,0, str(confun_matrix[0,1]), fontsize=22)\n",
    "plt.text(0.9,1, str(confun_matrix[1,1]), fontsize=22)\n",
    "plt.xticks([0, 1], ['周期', '非周期'], fontproperties='SimSun', fontsize=18)\n",
    "plt.yticks([0, 1], ['周期', '非周期'], fontproperties='SimSun', fontsize=18)\n",
    "plt.xlabel(\"预测值\", fontproperties='SimSun', fontsize=18)\n",
    "plt.ylabel(\"真实值\", fontproperties='SimSun', fontsize=18)\n",
    "plt.imshow(confun_matrix, cmap='Blues')\n",
    "plt.tight_layout()\n",
    "plt.colorbar()\n",
    "plt.savefig(r\"D:\\OneDrive\\桌面\\网络训练混淆矩阵.svg\", dpi=500)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'confusion_matrix'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[1;32mIn [42]\u001B[0m, in \u001B[0;36m<cell line: 9>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# Build graph with tf.confusion_matrix operation\u001B[39;00m\n\u001B[0;32m      8\u001B[0m sess \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mcompat\u001B[38;5;241m.\u001B[39mv1\u001B[38;5;241m.\u001B[39mInteractiveSession()\n\u001B[1;32m----> 9\u001B[0m op \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfusion_matrix\u001B[49m(y_true, y_pred)\n\u001B[0;32m     10\u001B[0m op2 \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mconfusion_matrix(y_true, y_pred, num_classes\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m6\u001B[39m, dtype\u001B[38;5;241m=\u001B[39mtf\u001B[38;5;241m.\u001B[39mfloat32, weights\u001B[38;5;241m=\u001B[39mtf\u001B[38;5;241m.\u001B[39mconstant([\u001B[38;5;241m0.3\u001B[39m, \u001B[38;5;241m0.4\u001B[39m, \u001B[38;5;241m0.3\u001B[39m]))\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# Execute the graph\u001B[39;00m\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'tensorflow' has no attribute 'confusion_matrix'"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "torch.save(model, 'MotionClassTwoCNN2024.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "CNN(\n  (Conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (Relu1): ReLU()\n  (Pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (Conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (Relu2): ReLU()\n  (Pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (Conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (Relu3): ReLU()\n  (Pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (Pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (Fc): Linear(in_features=9216, out_features=2, bias=True)\n)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = torch.load('MotionClassTwoCNN.pth', map_location=device)\n",
    "tt.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# pre1 = x_valid[77]\n",
    "pre1 = np.loadtxt(\"D:\\\\Data_Set\\\\pyVHR\\\\MovingClass\\\\Data\\\\1205_1.txt\")\n",
    "print(y_valid[77])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "tran = transforms.ToTensor()\n",
    "pre1 = tran(pre1).to(device)\n",
    "pre1 = pre1.view(1,1,513,151).to(torch.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-11.1065,  11.0189]], device='cuda:0', grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = tt(pre1)\n",
    "predict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(int(predict.argmax()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}