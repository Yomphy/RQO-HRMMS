{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import plotly.io as pio\n",
    "from pyVHR import extraction\n",
    "from pyVHR import datasets\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pio.renderers.default = 'browser'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    " import os\n",
    "\n",
    "# 递归遍历文件夹及其子文件夹下的所有txt文件\n",
    "def find_txt_files(folder_path):\n",
    "    txt_files = []\n",
    "\n",
    "    # 遍历文件夹中的所有文件和子文件夹\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        # 遍历当前文件夹中的所有文件\n",
    "        for file in files:\n",
    "            # 检查文件扩展名是否为txt\n",
    "            if file.endswith('.txt'):\n",
    "                # 构建txt文件的完整路径\n",
    "                txt_file_path = os.path.join(root, file)\n",
    "                if 'Lab' in txt_file_path[-10:]:\n",
    "                # 将txt文件路径添加到列表中\n",
    "                    txt_files.append(txt_file_path)\n",
    "\n",
    "    return txt_files\n",
    "\n",
    "# 指定文件夹路径\n",
    "folder_path = r\"F:\\Data Set\\pyVHR\\ECG_FITNESS Signal_good_video\"\n",
    "\n",
    "# 调用函数查找文件夹及其子文件夹下的所有txt文件\n",
    "txt_files = find_txt_files(folder_path)\n",
    "\n",
    "# 遍历输出找到的txt文件路径\n",
    "for file in txt_files:\n",
    "    print(file)\n",
    "print(len(txt_files))\n",
    "\n",
    "for file in txt_files:\n",
    "    try:\n",
    "        os.remove(file)\n",
    "        print(f\"文件 {file} 已成功删除\")\n",
    "    except OSError as e:\n",
    "        print(f\"删除文件 {file} 异常: {e}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_name = 'ecg_fitness'                              # 数据集名称\n",
    "video_DIR = r\"F:\\Data Set\\pyVHR\\ECG_FITNESS\"         # 视频数据目录的路径\n",
    "BVP_DIR = r\"F:\\Data Set\\pyVHR\\ECG_FITNESS\"             # 相应的BVP数据目录的路径\n",
    "\n",
    "w_size = 10                # 每次处理视频的滑窗长度 ，w_size=视频时长，则timesGT的第一个值对应的bpmGT中的心率就是对应整个视频时长的平均心率\n",
    "overlap = 1                # 相邻滑窗在时间上的重叠长度\n",
    "video_idx = 0              # 待处理视频的索引\n",
    "seconds = 0                # 处理视频的时长\n",
    "scal = 1.0                 # 视频尺寸缩放比例\n",
    "landmarks = extraction.MagicLandmarks.cheek_left_top \\\n",
    "            + extraction.MagicLandmarks.cheek_right_top   # 选择Landmark点\n",
    "\n",
    "dataset = datasets.datasetFactory(dataset_name, videodataDIR=video_DIR, BVPdataDIR=BVP_DIR)  # 读取对应数据集的类方法\n",
    "fname = dataset.getSigFilename(video_idx)     # 读取索引为video_idx的视频，这里的范围与上述的all_video有关\n",
    "sigGT = dataset.readSigfile(fname)            # 读取视频对应的BVP.gt数据\n",
    "test_bvp = sigGT.data\n",
    "bpmGT, timesGT = sigGT.getBPM(winsize=w_size)         # GT信息\n",
    "\n",
    "videoFileName = dataset.getVideoFilename(video_idx)\n",
    "fps = int(extraction.get_fps(videoFileName))\n",
    "\n",
    "# 定义信号提取方法\n",
    "sig_extractor = extraction.SignalProcessing()  # 创建一个可选用不同方法的用于提取信号的类\n",
    "sig_extractor.set_skin_extractor(extraction.SkinExtractionConvexHull())  # 设置提取人脸皮肤的方法，ConvexHull法\n",
    "sig_extractor.set_total_frames(seconds * fps)  # 得到需要处理的视频的帧数，seconds=0处理所有帧\n",
    "sig_extractor.set_landmarks(landmarks)\n",
    "sig_extractor.set_visualize_skin_and_landmarks(visualize_skin=True, visualize_landmarks=True,\n",
    "                                               visualize_landmarks_number=False, visualize_patch=True)  # 可视化参数设置\n",
    "sig_extractor.set_square_patches_side(10.0)  # 设置用于patches提取的矩形框尺寸\n",
    "\n",
    "print('All Videos: ', dataset.numVideos)\n",
    "print('Video processed name: ', videoFileName)\n",
    "print('Video frame rate:     ', fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_name = 'ecg_fitness'                              # 数据集名称\n",
    "video_DIR = r\"F:\\Data Set\\pyVHR\\ECG_FITNESS\"           # 视频数据目录的路径\n",
    "BVP_DIR = r\"F:\\Data Set\\pyVHR\\ECG_FITNESS\"             # 相应的BVP数据目录的路径\n",
    "\n",
    "seconds = 0                # 处理视频的时长\n",
    "landmarks = extraction.MagicLandmarks.cheek_left_top + extraction.MagicLandmarks.cheek_right_top   # 选择Landmark点\n",
    "# landmarks = [100, 119, 118, 117, 50, 36, 205, 207, 206, 348, 346, 347, 330, 280, 425, 426, 427, 411]\n",
    "\n",
    "sig_extractor = extraction.SignalProcessing()  # 创建一个可选用不同方法的用于提取信号的类\n",
    "sig_extractor.set_skin_extractor(extraction.SkinExtractionConvexHull())  # 设置提取人脸皮肤的方法，ConvexHull法\n",
    "sig_extractor.set_landmarks(landmarks)\n",
    "sig_extractor.set_visualize_skin_and_landmarks(visualize_skin=True, visualize_landmarks=True,\n",
    "                                               visualize_landmarks_number=False, visualize_patch=True)  # 可视化参数设置\n",
    "sig_extractor.set_square_patches_side(25.0)  # 设置用于patches提取的矩形框尺寸\n",
    "\n",
    "\n",
    "dataset = datasets.datasetFactory(dataset_name, videodataDIR=video_DIR, BVPdataDIR=BVP_DIR)  # 读取对应数据集的类方法\n",
    "count = dataset.numVideos\n",
    "print('All Videos: ', count)\n",
    "start_time0 = time.time()\n",
    "\n",
    "# for index in range(count):\n",
    "for index in range(1):\n",
    "    fname = dataset.getSigFilename(index)                        # 读取索引为video_idx的视频，这里的范围与上述的all_video有关\n",
    "    videoFileName = dataset.getVideoFilename(index)\n",
    "    fps = int(extraction.get_fps(videoFileName))\n",
    "    sig_extractor.set_total_frames(seconds * fps)                 # 得到需要处理的视频的帧数，seconds=0处理所有帧\n",
    "    print(index, ': ', videoFileName)\n",
    "    start_time1 = time.time()\n",
    "    # raw_rgb, motion_sig = sig_extractor.extract_patches(videoFileName, \"squares\", \"mean\")  # Patches方法\n",
    "    raw_rgb, motion_sig = sig_extractor.extract_holistic(videoFileName)                      # Holistic方法\n",
    "\n",
    "    # visualize_coll = sig_extractor.get_visualize_skin()           # patches可视化图像信号\n",
    "    # skin_area = []\n",
    "    # for skin in visualize_coll:\n",
    "    #     matrix_one = np.ones((skin.shape[0], skin.shape[1]))\n",
    "    #     matrix_and = np.logical_and(matrix_one, skin[:,:,0])\n",
    "    #     skin_area.append(sum(sum(matrix_and)))\n",
    "    # skin_area = np.array(skin_area)\n",
    "\n",
    "    # 将提取到的RGB信息与运动信息分别存储\n",
    "    txt_R_file = videoFileName[:-4] + '-R.txt'\n",
    "    txt_G_file = videoFileName[:-4] + '-G.txt'\n",
    "    txt_B_file = videoFileName[:-4] + '-B.txt'\n",
    "    np.savetxt(txt_R_file, raw_rgb[:, :, 0])\n",
    "    np.savetxt(txt_G_file, raw_rgb[:, :, 1])\n",
    "    np.savetxt(txt_B_file, raw_rgb[:, :, 2])\n",
    "\n",
    "    # txt_patches_file = videoFileName[:-4] + '-patch_index.txt'\n",
    "    # txt_X_file = videoFileName[:-4] + '-X_Motion.txt'\n",
    "    # txt_Y_file = videoFileName[:-4] + '-Y_Motion.txt'\n",
    "    # txt_Z_file = videoFileName[:-4] + '-Z_Motion.txt'\n",
    "\n",
    "    # np.savetxt(txt_patches_file, motion_sig[:, :, 0])\n",
    "    # np.savetxt(txt_X_file, motion_sig[:, :, 1])\n",
    "    # np.savetxt(txt_Y_file, motion_sig[:, :, 2])\n",
    "    # np.savetxt(txt_Z_file, skin_area)\n",
    "\n",
    "    end_time1 = time.time()\n",
    "    print('Get RGB signal time used :', end_time1 - start_time1)\n",
    "    print(' ')\n",
    "\n",
    "end_time0 = time.time()\n",
    "print('All time used :', end_time0 - start_time0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_name = 'ecg_fitness'                              # 数据集名称\n",
    "video_DIR = r\"E:\\Data Set\\pyVHR\\ECG_FITNESS\"           # 视频数据目录的路径\n",
    "BVP_DIR = r\"E:\\Data Set\\pyVHR\\ECG_FITNESS\"             # 相应的BVP数据目录的路径\n",
    "\n",
    "seconds = 0                # 处理视频的时长\n",
    "landmarks = extraction.MagicLandmarks.cheek_left_top + extraction.MagicLandmarks.cheek_right_top   # 选择Landmark点\n",
    "\n",
    "sig_extractor = extraction.SignalProcessing()  # 创建一个可选用不同方法的用于提取信号的类\n",
    "sig_extractor.set_skin_extractor(extraction.SkinExtractionConvexHull())  # 设置提取人脸皮肤的方法，ConvexHull法\n",
    "sig_extractor.set_landmarks(landmarks)\n",
    "sig_extractor.set_visualize_skin_and_landmarks(visualize_skin=True, visualize_landmarks=True,\n",
    "                                               visualize_landmarks_number=False, visualize_patch=True)  # 可视化参数设置\n",
    "sig_extractor.set_square_patches_side(10.0)  # 设置用于patches提取的矩形框尺寸\n",
    "\n",
    "\n",
    "dataset = datasets.datasetFactory(dataset_name, videodataDIR=video_DIR, BVPdataDIR=BVP_DIR)  # 读取对应数据集的类方法\n",
    "count = dataset.numVideos\n",
    "print('All Videos: ', count)\n",
    "start_time0 = time.time()\n",
    "\n",
    "for index in range(count):\n",
    "    fname = dataset.getSigFilename(index)                        # 读取索引为video_idx的视频，这里的范围与上述的all_video有关\n",
    "    videoFileName = dataset.getVideoFilename(index)\n",
    "    fps = int(extraction.get_fps(videoFileName))\n",
    "    sig_extractor.set_total_frames(seconds * fps)                 # 得到需要处理的视频的帧数，seconds=0处理所有帧\n",
    "    print(index, ': ', videoFileName)\n",
    "    start_time1 = time.time()\n",
    "    raw_rgb, motion_sig = sig_extractor.extract_patches(videoFileName, \"squares\", \"mean\")  # Patches方法\n",
    "    # raw_rgb, motion_sig = sig_extractor.extract_holistic(videoFileName)                      # Holistic方法\n",
    "\n",
    "    visualize_coll = sig_extractor.get_visualize_skin()           # patches可视化图像信号\n",
    "    skin_area = []\n",
    "    for skin in visualize_coll:\n",
    "        matrix_one = np.ones((skin.shape[0], skin.shape[1]))\n",
    "        matrix_and = np.logical_and(matrix_one, skin[:,:,0])\n",
    "        skin_area.append(sum(sum(matrix_and)))\n",
    "    skin_area = np.array(skin_area)\n",
    "\n",
    "    # 将提取到的RGB信息与运动信息分别存储\n",
    "    txt_R_file = videoFileName[:-4] + '-R.txt'\n",
    "    txt_G_file = videoFileName[:-4] + '-G.txt'\n",
    "    txt_B_file = videoFileName[:-4] + '-B.txt'\n",
    "    np.savetxt(txt_R_file, raw_rgb[:, :, 0])\n",
    "    np.savetxt(txt_G_file, raw_rgb[:, :, 1])\n",
    "    np.savetxt(txt_B_file, raw_rgb[:, :, 2])\n",
    "\n",
    "    end_time1 = time.time()\n",
    "    print('Get RGB signal time used :', end_time1 - start_time1)\n",
    "    print(' ')\n",
    "\n",
    "end_time0 = time.time()\n",
    "print('All time used :', end_time0 - start_time0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "r = np.loadtxt(\"E:\\\\Data Set\\\\pyVHR\\\\ECG_FITNESS\\\\00\\\\01\\\\c920-1-R.txt\")\n",
    "g = np.loadtxt(\"E:\\\\Data Set\\\\pyVHR\\\\ECG_FITNESS\\\\00\\\\01\\\\c920-1-G.txt\")\n",
    "b = np.loadtxt(\"E:\\\\Data Set\\\\pyVHR\\\\ECG_FITNESS\\\\00\\\\01\\\\c920-1-B.txt\")\n",
    "\n",
    "inx = np.loadtxt(\"E:\\\\Data Set\\\\pyVHR\\\\ECG_FITNESS\\\\00\\\\01\\\\c920-1-patch_index.txt\")\n",
    "x = np.loadtxt(\"E:\\\\Data Set\\\\pyVHR\\\\ECG_FITNESS\\\\00\\\\01\\\\c920-1-X_Motion.txt\")\n",
    "y = np.loadtxt(\"E:\\\\Data Set\\\\pyVHR\\\\ECG_FITNESS\\\\00\\\\01\\\\c920-1-Y_Motion.txt\")\n",
    "\n",
    "rgb = np.array([[r,g,b]]).transpose((2, 0, 1))\n",
    "mm = np.array([inx, x, y], np.int).transpose((1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_name = 'ecg_fitness'                              # 数据集名称\n",
    "video_DIR = r\"E:\\Data Set\\pyVHR\\ECG_FITNESS\"           # 视频数据目录的路径\n",
    "BVP_DIR = r\"E:\\Data Set\\pyVHR\\ECG_FITNESS\"             # 相应的BVP数据目录的路径\n",
    "\n",
    "seconds = 0                # 处理视频的时长\n",
    "landmarks = extraction.MagicLandmarks.cheek_left_top + extraction.MagicLandmarks.cheek_right_top   # 选择Landmark点\n",
    "\n",
    "sig_extractor = extraction.SignalProcessing()  # 创建一个可选用不同方法的用于提取信号的类\n",
    "sig_extractor.set_skin_extractor(extraction.SkinExtractionConvexHull())  # 设置提取人脸皮肤的方法，ConvexHull法\n",
    "sig_extractor.set_landmarks(landmarks)\n",
    "sig_extractor.set_visualize_skin_and_landmarks(visualize_skin=True, visualize_landmarks=True,\n",
    "                                               visualize_landmarks_number=False, visualize_patch=True)  # 可视化参数设置\n",
    "sig_extractor.set_square_patches_side(10.0)  # 设置用于patches提取的矩形框尺寸\n",
    "\n",
    "\n",
    "dataset = datasets.datasetFactory(dataset_name, videodataDIR=video_DIR, BVPdataDIR=BVP_DIR)  # 读取对应数据集的类方法\n",
    "count = dataset.numVideos\n",
    "print('All Videos: ', count)\n",
    "start_time0 = time.time()\n",
    "\n",
    "for index in range(count):\n",
    "    fname = dataset.getSigFilename(index)                        # 读取索引为video_idx的视频，这里的范围与上述的all_video有关\n",
    "    videoFileName = dataset.getVideoFilename(index)\n",
    "    fps = int(extraction.get_fps(videoFileName))\n",
    "    sig_extractor.set_total_frames(seconds * fps)                 # 得到需要处理的视频的帧数，seconds=0处理所有帧\n",
    "    print(index, ': ', videoFileName)\n",
    "    start_time1 = time.time()\n",
    "    raw_Lab, _ = sig_extractor.extract_holistic(videoFileName)                      # Holistic方法\n",
    "\n",
    "    visualize_coll = sig_extractor.get_visualize_skin()           # patches可视化图像信号\n",
    "    skin_area = []\n",
    "    for skin in visualize_coll:\n",
    "        matrix_one = np.ones((skin.shape[0], skin.shape[1]))\n",
    "        matrix_and = np.logical_and(matrix_one, skin[:,:,0])\n",
    "        skin_area.append(sum(sum(matrix_and)))\n",
    "    skin_area = np.array(skin_area)\n",
    "\n",
    "    # 将提取到的Lab信息与运动信息分别存储\n",
    "    txt_L_file = videoFileName[:29] + ' Signal' + videoFileName[29:-4] + '-Lab_L.txt'\n",
    "    txt_a_file = videoFileName[:29] + ' Signal' + videoFileName[29:-4] + '-Lab_a.txt'\n",
    "    txt_b_file = videoFileName[:29] + ' Signal' + videoFileName[29:-4] + '-Lab_b.txt'\n",
    "    np.savetxt(txt_L_file, raw_Lab[:, :, 0])\n",
    "    np.savetxt(txt_a_file, raw_Lab[:, :, 1])\n",
    "    np.savetxt(txt_b_file, raw_Lab[:, :, 2])\n",
    "\n",
    "    end_time1 = time.time()\n",
    "    print('Get RGB signal time used :', end_time1 - start_time1)\n",
    "    print(' ')\n",
    "\n",
    "end_time0 = time.time()\n",
    "print('All time used :', end_time0 - start_time0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_name = 'ecg_fitness'                              # 数据集名称\n",
    "video_DIR = r\"D:\\Data_Set\\pyVHR\\ECG_FITNESS Signal\"         # 视频数据目录的路径\n",
    "BVP_DIR = r\"D:\\Data_Set\\pyVHR\\ECG_FITNESS Signal\"             # 相应的BVP数据目录的路径\n",
    "\n",
    "seconds = 0                # 处理视频的时长\n",
    "landmarks = extraction.MagicLandmarks.cheek_left_top + extraction.MagicLandmarks.cheek_right_top   # 选择Landmark点\n",
    "\n",
    "sig_extractor = extraction.SignalProcessing()  # 创建一个可选用不同方法的用于提取信号的类\n",
    "sig_extractor.set_skin_extractor(extraction.SkinExtractionConvexHull())  # 设置提取人脸皮肤的方法，ConvexHull法\n",
    "sig_extractor.set_landmarks(landmarks)\n",
    "sig_extractor.set_visualize_skin_and_landmarks(visualize_skin=True, visualize_landmarks=True,\n",
    "                                               visualize_landmarks_number=False, visualize_patch=True)  # 可视化参数设置\n",
    "sig_extractor.set_square_patches_side(10.0)  # 设置用于patches提取的矩形框尺寸\n",
    "\n",
    "\n",
    "dataset = datasets.datasetFactory(dataset_name, videodataDIR=video_DIR, BVPdataDIR=BVP_DIR)  # 读取对应数据集的类方法\n",
    "count = dataset.numVideos\n",
    "print('All Videos: ', count)\n",
    "start_time0 = time.time()\n",
    "hr_gt = []\n",
    "for index in range(count):\n",
    "    fname = dataset.getSigFilename(index)                        # 读取索引为video_idx的视频，这里的范围与上述的all_video有关\n",
    "    try:\n",
    "        sigGT = dataset.readSigfile(fname)            # 读取视频对应的BVP.gt数据\n",
    "    except:\n",
    "        continue\n",
    "    test_bvp = sigGT.data\n",
    "    bpmGT, timesGT = sigGT.getBPM(winsize=20)         # GT信息\n",
    "    hr_gt.append(np.array(bpmGT))\n",
    "    print(index, ' : ', fname)\n",
    "\n",
    "end_time0 = time.time()\n",
    "print('All time used :', end_time0 - start_time0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hr_60 = []\n",
    "for hr in hr_gt:\n",
    "    if len(hr) > 60:\n",
    "        ti = np.linspace(0, len(hr)-1, num=60, dtype=np.int16)\n",
    "        hr_60.append(hr[ti])\n",
    "    else:\n",
    "        hr_60.append(hr)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hr_delta = []\n",
    "hr_delta_mu = []\n",
    "hr_delta_std = []\n",
    "for hr in hr_60:\n",
    "    delta = abs(hr[1:] - hr[:-1]) / 60\n",
    "    hr_delta.append(delta)\n",
    "    hr_delta_mu.append(np.mean(delta))\n",
    "    hr_delta_std.append(np.std(delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hr_mean = np.mean(hr_delta_mu)\n",
    "hr_std = np.std(hr_delta_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_name = 'ecg_fitness'                              # 数据集名称\n",
    "video_DIR = r\"D:\\Data_Set\\pyVHR\\ECG_FITNESS Signal\"         # 视频数据目录的路径\n",
    "BVP_DIR = r\"D:\\Data_Set\\pyVHR\\ECG_FITNESS Signal\"             # 相应的BVP数据目录的路径\n",
    "\n",
    "w_size = 20                # 每次处理视频的滑窗长度 ，w_size=视频时长，则timesGT的第一个值对应的bpmGT中的心率就是对应整个视频时长的平均心率\n",
    "overlap = 1                # 相邻滑窗在时间上的重叠长度\n",
    "video_idx = 7          # 待处理视频的索引\n",
    "seconds = 0                # 处理视频的时长\n",
    "scal = 1.0                 # 视频尺寸缩放比例\n",
    "landmarks = extraction.MagicLandmarks.cheek_left_top \\\n",
    "            + extraction.MagicLandmarks.cheek_right_top   # 选择Landmark点\n",
    "\n",
    "dataset = datasets.datasetFactory(dataset_name, videodataDIR=video_DIR, BVPdataDIR=BVP_DIR)  # 读取对应数据集的类方法\n",
    "fname = dataset.getSigFilename(video_idx)     # 读取索引为video_idx的视频，这里的范围与上述的all_video有关\n",
    "videoFileName = dataset.getVideoFilename(video_idx)\n",
    "\n",
    "print('All Videos: ', dataset.numVideos)\n",
    "print('Video processed name: ', videoFileName)\n",
    "fig = go.Figure()\n",
    "\n",
    "for index in range(dataset.numVideos):\n",
    "    fname = dataset.getSigFilename(index)                        # 读取索引为video_idx的视频，这里的范围与上述的all_video有关\n",
    "    try:\n",
    "        sigGT = dataset.readSigfile(fname)            # 读取视频对应的BVP.gt数据\n",
    "    except:\n",
    "        continue\n",
    "    videoFileName = dataset.getVideoFilename(index)\n",
    "    X_data_file = videoFileName[:-4] + \"-1-X_Motion.txt\"\n",
    "    Y_data_file = videoFileName[:-4] + \"-1-Y_Motion.txt\"\n",
    "    Z_data_file = videoFileName[:-4] + \"-1-Z_Motion.txt\"\n",
    "\n",
    "    x_data = np.loadtxt(X_data_file)\n",
    "    y_data = np.loadtxt(Y_data_file)\n",
    "    z_data = np.loadtxt(Z_data_file)\n",
    "    x_name = videoFileName[-14:-9] + \"-X\"\n",
    "    y_name = videoFileName[-14:-9] + \"-Y\"\n",
    "    z_name = videoFileName[-14:-9] + \"-Z\"\n",
    "\n",
    "    r_color = random.randint(1, 255)\n",
    "    g_color = random.randint(1, 255)\n",
    "    b_color = random.randint(1, 255)\n",
    "    fig.add_trace(go.Scatter(x=np.arange(x_data.shape[-1]), y=x_data[0],\n",
    "                             mode='lines', marker_color='rgba(' + str(r_color) + ', ' + str(g_color) + ', ' + str(b_color) + ', 1.0)', name=x_name))\n",
    "    fig.add_trace(go.Scatter(x=np.arange(y_data.shape[-1]), y=y_data[0],\n",
    "                             mode='lines', marker_color='rgba(' + str(r_color) + ', ' + str(g_color) + ', ' + str(b_color) + ', 1.0)', name=y_name))\n",
    "    fig.add_trace(go.Scatter(x=np.arange(z_data.shape[-1]), y=z_data,\n",
    "                             mode='lines', marker_color='rgba(' + str(r_color) + ', ' + str(g_color) + ', ' + str(b_color) + ', 1.0)', name=z_name))\n",
    "\n",
    "fig.update_layout(title='Motion')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_name = 'ecg_fitness'                              # 数据集名称\n",
    "video_DIR = r\"D:\\Data_Set\\pyVHR\\ECG_FITNESS Signal\"         # 视频数据目录的路径\n",
    "BVP_DIR = r\"D:\\Data_Set\\pyVHR\\ECG_FITNESS Signal\"             # 相应的BVP数据目录的路径\n",
    "\n",
    "w_size = 20                # 每次处理视频的滑窗长度 ，w_size=视频时长，则timesGT的第一个值对应的bpmGT中的心率就是对应整个视频时长的平均心率\n",
    "overlap = 1                # 相邻滑窗在时间上的重叠长度\n",
    "video_idx = 0          # 待处理视频的索引\n",
    "seconds = 0                # 处理视频的时长\n",
    "scal = 1.0                 # 视频尺寸缩放比例\n",
    "landmarks = extraction.MagicLandmarks.cheek_left_top \\\n",
    "            + extraction.MagicLandmarks.cheek_right_top   # 选择Landmark点\n",
    "\n",
    "dataset = datasets.datasetFactory(dataset_name, videodataDIR=video_DIR, BVPdataDIR=BVP_DIR)  # 读取对应数据集的类方法\n",
    "fname = dataset.getSigFilename(video_idx)     # 读取索引为video_idx的视频，这里的范围与上述的all_video有关\n",
    "videoFileName = dataset.getVideoFilename(video_idx)\n",
    "\n",
    "print('All Videos: ', dataset.numVideos)\n",
    "print('Video processed name: ', videoFileName)\n",
    "x = []\n",
    "y = []\n",
    "z = []\n",
    "for index in range(dataset.numVideos):\n",
    "    fname = dataset.getSigFilename(index)                        # 读取索引为video_idx的视频，这里的范围与上述的all_video有关\n",
    "    try:\n",
    "        sigGT = dataset.readSigfile(fname)            # 读取视频对应的BVP.gt数据\n",
    "    except:\n",
    "        continue\n",
    "    videoFileName = dataset.getVideoFilename(index)\n",
    "    X_data_file = videoFileName[:-4] + \"-1-X_Motion.txt\"\n",
    "    Y_data_file = videoFileName[:-4] + \"-1-Y_Motion.txt\"\n",
    "    Z_data_file = videoFileName[:-4] + \"-1-Z_Motion.txt\"\n",
    "\n",
    "    x_data = np.loadtxt(X_data_file)\n",
    "    y_data = np.loadtxt(Y_data_file)\n",
    "    z_data = np.loadtxt(Z_data_file)\n",
    "    x_name = videoFileName[-14:-9] + \"-X\"\n",
    "    y_name = videoFileName[-14:-9] + \"-Y\"\n",
    "    z_name = videoFileName[-14:-9] + \"-Z\"\n",
    "\n",
    "    r_color = random.randint(1, 255)\n",
    "    g_color = random.randint(1, 255)\n",
    "    b_color = random.randint(1, 255)\n",
    "    x.append((np.std(x_data[0])))\n",
    "    y.append((np.std(y_data[0])))\n",
    "    z.append((np.std(z_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(x)), y=x, mode='lines', name='x_std'))\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(y)), y=y, mode='lines', name='y_std'))\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(z)), y=z, mode='lines', name='z_std'))\n",
    "\n",
    "fig.update_layout(title='Motion')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_name = 'ecg_fitness'                              # 数据集名称\n",
    "video_DIR = r\"D:\\Data_Set\\pyVHR\\ECG_FITNESS Signal\"         # 视频数据目录的路径\n",
    "BVP_DIR = r\"D:\\Data_Set\\pyVHR\\ECG_FITNESS Signal\"             # 相应的BVP数据目录的路径\n",
    "\n",
    "w_size = 20                # 每次处理视频的滑窗长度 ，w_size=视频时长，则timesGT的第一个值对应的bpmGT中的心率就是对应整个视频时长的平均心率\n",
    "overlap = 1                # 相邻滑窗在时间上的重叠长度\n",
    "video_idx = 11              # 待处理视频的索引\n",
    "seconds = 0                # 处理视频的时长\n",
    "scal = 1.0                 # 视频尺寸缩放比例\n",
    "landmarks = extraction.MagicLandmarks.cheek_left_top \\\n",
    "            + extraction.MagicLandmarks.cheek_right_top   # 选择Landmark点\n",
    "\n",
    "dataset = datasets.datasetFactory(dataset_name, videodataDIR=video_DIR, BVPdataDIR=BVP_DIR)  # 读取对应数据集的类方法\n",
    "fname = dataset.getSigFilename(video_idx)     # 读取索引为video_idx的视频，这里的范围与上述的all_video有关\n",
    "videoFileName = dataset.getVideoFilename(video_idx)\n",
    "fps = 30\n",
    "print('All Videos: ', dataset.numVideos)\n",
    "print('Video processed name: ', videoFileName)\n",
    "\n",
    "index_data_file = videoFileName[:-4] + \"-1-patch_index.txt\"\n",
    "X_data_file = videoFileName[:-4] + \"-1-X_Motion.txt\"\n",
    "Y_data_file = videoFileName[:-4] + \"-1-Y_Motion.txt\"\n",
    "Z_data_file = videoFileName[:-4] + \"-1-Z_Motion.txt\"\n",
    "inx_data = np.loadtxt(index_data_file)\n",
    "x_data = np.loadtxt(X_data_file)\n",
    "y_data = np.loadtxt(Y_data_file)\n",
    "z_data = np.loadtxt(Z_data_file)\n",
    "\n",
    "motion_sig = np.array([inx_data, x_data, y_data], np.int32).transpose((1, 2, 0))\n",
    "speed_x, speed_y, acc_x, acc_y = speed_acc_sig(motion_sig, fps)  # 数组形式速度、加速度信号\n",
    "speed_x_sum, speed_y_sum, acc_x_sum, acc_y_sum, motion_sum = sum_speed_acc_sig(speed_x, speed_y, acc_x, acc_y, motion_sig)  # patches速度加速度求和\n",
    "motion_z = z_data\n",
    "speed_z_sum = np.array([np.zeros_like(motion_z)])\n",
    "speed_z_sum[0, 1:] = np.array((motion_z[1:] - motion_z[0:-1]) * fps)\n",
    "speed_sum = np.vstack([speed_x_sum, speed_y_sum, speed_z_sum])\n",
    "speed_sum = np.expand_dims(speed_sum, axis = 2).transpose((1, 2, 0))\n",
    "\n",
    "win_speed, times_ES = extraction.sig_windowing(speed_sum, 10, stride=1, fps=fps)\n",
    "x_mean = []\n",
    "y_mean = []\n",
    "z_mean = []\n",
    "for sig in win_speed:\n",
    "    sig = np.squeeze(sig)\n",
    "    x_mean.append(np.mean(abs(sig[0])))\n",
    "    y_mean.append(np.mean(abs(sig[1])))\n",
    "    z_mean.append(np.mean(abs(sig[2])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(x_mean)), y=x_mean, mode='lines', name='x_std'))\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(y_mean)), y=y_mean, mode='lines', name='y_std'))\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(z_mean)), y=z_mean, mode='lines', name='z_std'))\n",
    "\n",
    "fig.update_layout(title='Speed-' + str(videoFileName[-11:-9]))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyvhr-cpu]",
   "language": "python",
   "name": "pyvhr-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
